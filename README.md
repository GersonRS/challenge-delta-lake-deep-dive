<!--
*** Obrigado por estar vendo o nosso README. Se voc√™ tiver alguma sugest√£o
*** que possa melhor√°-lo ainda mais d√™ um fork no reposit√≥rio e crie uma Pull
*** Request ou abra uma Issue com a tag "sugest√£o".
*** Obrigado novamente! Agora vamos rodar esse projeto incr√≠vel :D
-->

<!-- PROJECT SHIELDS -->

[![npm](https://img.shields.io/badge/type-Open%20Project-green?&style=plastic)](https://img.shields.io/badge/type-Open%20Project-green)
[![GitHub last commit](https://img.shields.io/github/last-commit/GersonRS/challenge-delta-lake-deep-dive?logo=github&style=plastic)](https://github.com/GersonRS/challenge-delta-lake-deep-dive/commits/master)
[![GitHub Issues](https://img.shields.io/github/issues/gersonrs/challenge-delta-lake-deep-dive?logo=github&style=plastic)](https://github.com/GersonRS/challenge-delta-lake-deep-dive/issues)
[![GitHub Language](https://img.shields.io/github/languages/top/gersonrs/challenge-delta-lake-deep-dive?&logo=github&style=plastic)](https://github.com/GersonRS/challenge-delta-lake-deep-dive/search?l=python)
[![GitHub Repo-Size](https://img.shields.io/github/repo-size/GersonRS/challenge-delta-lake-deep-dive?logo=github&style=plastic)](https://img.shields.io/github/repo-size/GersonRS/challenge-delta-lake-deep-dive)
[![GitHub Contributors](https://img.shields.io/github/contributors/GersonRS/challenge-delta-lake-deep-dive?logo=github&style=plastic)](https://img.shields.io/github/contributors/GersonRS/challenge-delta-lake-deep-dive)
[![GitHub Stars](https://img.shields.io/github/stars/GersonRS/challenge-delta-lake-deep-dive?logo=github&style=plastic)](https://img.shields.io/github/stars/GersonRS/challenge-delta-lake-deep-dive)
[![NPM](https://img.shields.io/github/license/GersonRS/challenge-delta-lake-deep-dive?&style=plastic)](LICENSE)
[![Status](https://img.shields.io/badge/status-active-success.svg)](https://img.shields.io/badge/status-active-success.svg)

<p align="center">
  <img alt="logo" src="https://github.com/GersonRS/react-native-template-gersonrsantos-basic/raw/main/assets/logo.png"/>
</p>

<!-- PROJECT LOGO -->
<br />
<p align="center">
  <a href="https://theplumbers.com.br/">
    <img src="https://avatars.githubusercontent.com/u/100875314?s=200&v=4" alt="Logo">
  </a>

  <h3 align="center">https://theplumbers.com.br/</h3>
</p>

<!-- TABLE OF CONTENTS -->

# Tabela de Conte√∫do

- [Tabela de Conte√∫do](#tabela-de-conte%C3%BAdo)
- [Sobre o Projeto](#sobre-o-projeto)
- [Feito Com](#feito-com)
- [Fluxo de versionamento](#fluxo-de-versionamento)
- [Come√ßando](#come%C3%A7ando)
  - [Pr√©-requisitos](#pr%C3%A9-requisitos)
  - [Instala√ß√£o do cluster](#instala%C3%A7%C3%A3o-do-cluster)
  - [Instala√ß√£o das ferramentas](#instala%C3%A7%C3%A3o-das-ferramentas)
  - [Executando o projeto](#executando-o-projeto)
- [Estrutura de Arquivos](#estrutura-de-arquivos)
  - [Edi√ß√£o](#edi%C3%A7%C3%A3o)
- [Contribui√ß√£o](#contribui%C3%A7%C3%A3o)
- [Licen√ßa](#licen%C3%A7a)
- [Contato](#contato)

<!-- ABOUT THE PROJECT -->

# Sobre o Projeto


O projeto visa solucionar o [desafio do workshop "Construindo seu pr√≥prio Data Lakehouse usando o Delta Lake"](https://github.com/GersonRS/ws-delta-lake-deep-dive/tree/main/challenge), que consiste em criar um pipeline de dados usando a arquitetura Medalion (Bronze, Silver e Gold), utilizando o Delta Lake.

O objetivo deste reposit√≥rio √© detalhar a cria√ß√£o de uma `prova de conceito` (`POC`) que soluciona o `desafio`, independentemente das tecnologias utilizadas. Ele visa criar um pipeline de dados que use a arquitetura **`Bronze`**, **`Silver`** e **`Gold`**, que possa ser utilizado como uma `POC` e um ponto de partida para projetos mais complexos, visto que o processo de cria√ß√£o e configura√ß√£o de um pipeline de dados que segue essa arquitetura pode gerar complexidade e muitas vezes erros que atrasam o processo, atrapalhando o fluxo de desenvolvimento. A arquitetura em camadas `medalion` √© √∫til para garantir a qualidade dos dados e permitir que diferentes times possam acessar e usar dados em diferentes n√≠veis de agrega√ß√£o.

# Fluxo de versionamento:
Projeto segue regras de versionamento [gitflow](https://www.atlassian.com/br/git/tutorials/comparing-workflows/gitflow-workflow).

# Feito Com

Abaixo segue o que foi utilizado na cria√ß√£o deste projeto:

- [Minikube](https://minikube.sigs.k8s.io/docs/start/) - Ferramenta de c√≥digo aberto que permite criar um ambiente de teste do Kubernetes em sua m√°quina local. Com o Minikube, √© poss√≠vel criar e implantar aplicativos em um cluster Kubernetes em sua m√°quina local.
- [Helm](https://helm.sh/) - Ferramenta de gerenciamento de pacotes de c√≥digo aberto para o Kubernetes. O Helm permite empacotar aplicativos Kubernetes em um formato padr√£o chamado de gr√°fico, que inclui todos os recursos necess√°rios para implantar o aplicativo, incluindo configura√ß√µes e depend√™ncias.
- [ArgoCD](https://argo-cd.readthedocs.io/en/stable/) - Ferramenta declarativa que usa a abordagem GitOps para implantar aplica√ß√µes no Kubernetes. O Argo CD √© gratuito, tem c√≥digo aberto, √© um projeto incubado pela CNCF, e possui uma interface web de visualiza√ß√£o e gerenciamento dos recursos, mas tamb√©m pode ser configurado via linha de comando.
- [Spark](https://spark.apache.org/) - O Spark √© um framework de processamento de dados distribu√≠do e de c√≥digo aberto, que permite executar processamento de dados em larga escala, incluindo processamento em batch, streaming, SQL, machine learning e processamento de gr√°ficos. Ele foi projetado para ser executado em clusters de computadores e fornece uma interface de programa√ß√£o f√°cil de usar para desenvolvedores;
- [Airflow](https://airflow.apache.org/) - O Airflow √© uma plataforma de orquestra√ß√£o de fluxo de trabalho de dados de c√≥digo aberto que permite criar, agendar e monitorar fluxos de trabalho complexos de processamento de dados. Ele usa uma linguagem de defini√ß√£o de fluxo de trabalho baseada em Python e possui uma ampla gama de conectores pr√©-constru√≠dos para trabalhar com diferentes sistemas de armazenamento de dados, bancos de dados e ferramentas de processamento de dados;
- [Reflector](https://github.com/emberstack/kubernetes-reflector) - O Reflector √© uma ferramenta de sincroniza√ß√£o de estado de c√≥digo aberto que permite sincronizar recursos Kubernetes em diferentes clusters ou namespaces. Ele usa a abordagem de controlador de reconcilia√ß√£o para monitorar e atualizar automaticamente o estado dos recursos Kubernetes com base em um estado desejado especificado;
- [Minio](https://min.io/) - O Minio √© um sistema de armazenamento de objetos de c√≥digo aberto e de alta performance, compat√≠vel com a API Amazon S3. Ele √© projetado para ser executado em clusters distribu√≠dos e escal√°veis e fornece recursos avan√ßados de seguran√ßa e gerenciamento de dados;
- [Postgres](https://www.postgresql.org/) - O Postgres √© um sistema de gerenciamento de banco de dados relacional de c√≥digo aberto, conhecido por sua confiabilidade, escalabilidade e recursos avan√ßados de seguran√ßa. Ele √© compat√≠vel com SQL e √© usado em uma ampla gama de aplicativos, desde pequenos sites at√© grandes empresas e organiza√ß√µes governamentais.

<!-- GETTING STARTED -->

# Come√ßando

Antes de executar o pipeline de dados, √© necess√°rio instalar algumas aplica√ß√µes que ser√£o respons√°veis por manter e gerenciar o processo. Este guia apresentar√° uma s√©rie de comandos para instalar as ferramentas necess√°rias.
## Pr√©-requisitos

Antes de prosseguir com a configura√ß√£o e uso da solu√ß√£o, voc√™ precisar√° fazer um **`fork`** deste projeto e configurar um ambiente de desenvolvimento local para criar, testar e executar o projeto e ter uma chave ssh configurada em seu computador. Para isso, siga o guia abaixo:

### instala√ß√£o do cluster

O primeiro passo √© montar um ambiente com um cluster Kubernetes local para executar a aplica√ß√£o e o pipeline de dados. Para esta POC, usaremos o cluster de Kubernetes **[minikube](https://minikube.sigs.k8s.io/docs/)**. [Siga este guia de instala√ß√£o para instalar o Minikube](https://minikube.sigs.k8s.io/docs/start/).

Tamb√©m usaremos o **[helm](https://helm.sh/)** para nos ajudar a instalar algumas aplica√ß√µes. [Siga este guia de instala√ß√£o para instalar o Helm](https://helm.sh/docs/intro/install/).

Ap√≥s instalar esses pr√©-requisitos, √© hora de iniciar o nosso cluster Minikube. Para que tudo ocorra bem, √© aconselh√°vel usar um cluster de no m√≠nimo 8GB de mem√≥ria e 2 CPUs. Execute o seguinte comando no terminal:

```
minikube start --memory=8000 --cpus=2
```

Para acessar alguns servi√ßos via loadbalancer no Minikube, √© necess√°rio utilizar o [tunelamento do minikube](https://minikube.sigs.k8s.io/docs/handbook/accessing/#example-of-loadbalancer). Para isso, abra uma nova aba no seu terminal e execute o seguinte comando:
```sh
minikube tunnel
```

Com isso, o seu ambiente estar√° pronto para receber acessos via loadbalancer.

### Instala√ß√£o das ferramentas

Depois do ambiente inicializado ser√° necessario instalar algumas aplica√ß√µes que ser√£o responsaveis por manter e gerenciar nosso pipeline de dados.

Estando conectado em um cluster Kubernetes, execute os seguintes comandos para criar todos os namespaces necessarios:

```sh
kubectl create namespace orchestrator
kubectl create namespace database
kubectl create namespace ingestion
kubectl create namespace processing
kubectl create namespace datastore
kubectl create namespace deepstorage
kubectl create namespace cicd
kubectl create namespace app
kubectl create namespace management
kubectl create namespace misc
```

Instale o argocd que ser√° responsavel por manter nossas aplica√ß√µes:
```sh
helm repo add argo https://argoproj.github.io/argo-helm
helm repo update
helm install argocd argo/argo-cd --namespace cicd --version 5.27.1
```

Altere o service do argo para loadbalancer:
```sh
# create a load balancer
kubectl patch svc argocd-server -n cicd -p '{"spec": {"type": "LoadBalancer"}}'
```

Em seguida instale o argo cli para fazer a configura√ß√£o do repositorio:
```sh
sudo curl -sSL -o /usr/local/bin/argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
sudo chmod +x /usr/local/bin/argocd
```
Em seguida armazene o ip atribiudo para acessar o argo e fa√ßa o login no argo, com os seguintes comandos:
```sh
ARGOCD_LB=$(kubectl get services -n cicd -l app.kubernetes.io/name=argocd-server,app.kubernetes.io/instance=argocd -o jsonpath="{.items[0].status.loadBalancer.ingress[0].ip}")

# get password to log into argocd portal
# argocd login 192.168.0.200 --username admin --password UbV0FdJ2ZNCD8kxU --insecure
kubectl get secret argocd-initial-admin-secret -n cicd -o jsonpath="{.data.password}" | base64 -d | xargs -t -I {} argocd login $ARGOCD_LB --username admin --password {} --insecure
```
> caso queira ver o password do argo para acessar a interface web execute este comando: `kubectl get secret argocd-initial-admin-secret -n cicd -o jsonpath="{.data.password}" | base64 -d`

Uma vez feita a autentica√ß√£o n√£o √© necessario adicionar um cluster, pois o argo esta configurado para usar o cluster em que ele esta instalado, ou seja, o cluster local ja esta adicionado como **`--in-cluster`**, bastando apenas adicionar o seu repositorio com o seguinte comando:

```sh
argocd repo add git@github.com:GersonRS/big-data-on-k8s.git --ssh-private-key-path ~/.ssh/id_ed25519 --insecure-skip-server-verification
```

> Lembrando que para este comando funcionar √© necessario que voc√™ tenha uma `chave ssh` configurada para se conectar com o github no seu computador. Caso n√£o tenha, use [este guia](https://docs.github.com/pt/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent) para criar uma e [adiciona-la ao github](https://docs.github.com/pt/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account).

√â hora de adicionar as ferramentas necess√°rias para o pipeline de dados. Para isso, √© preciso criar secrets para armazenar senhas e informa√ß√µes confidenciais acess√≠veis pelas aplica√ß√µes e processos do Spark. √â necess√°rio que eles estejam no namespace onde a aplica√ß√£o est√° rodando e tamb√©m no namespace processing, onde ser√£o executados os processos do spark. Para realizar essa replica√ß√£o dos secrets em diferentes namespaces, podemos usar o **[Reflactor](https://github.com/EmberStack/kubernetes-reflector)**, que evita a necessidade de recriar os secrets em namespaces diferentes. Para utiliz√°-lo, basta executar o comando a seguir:

Agora √© hora de adicionar as outras ferramentas necesarias para o nosso pipeline de dados. E para isto precisamos criar `secrets` para armazenar senhas e informa√ß√µes censiveis, que  sejam acessiveis pelas aplica√ß√µes e processos do **`Spark`**, por isso √© necessario que eles estejam no namespace onde esta rodando a aplica√ß√£o e tamb√©m no namespace processing, onde ser√° executado os processos do `spark`. Ent√£o para isto podemos usar o **[Reflactor](https://github.com/EmberStack/kubernetes-reflector)**, que ajudar√° a replicar os secrets nos namespaces necess√°rios e a manter a seguran√ßa dos dados. Al√©m disso, os comandos para instalar as configura√ß√µes de acesso s√£o importantes para garantir que apenas as pessoas autorizadas possam acessar os recursos do seu cluster, e para isto execute este comando:

```sh
kubectl apply -f manifests/management/reflector.yaml
```

> Antes de executar os comandos, voc√™ pode alterar os secrets dos arquivos localizados na pasta `secrets/` se quiser mudar as senhas de acesso aos bancos de dados e ao storage.

Ap√≥s o Reflector estar funcionando, execute o comando que cria os secrets nos namespaces necess√°rios:

```sh
# secrets
kubectl apply -f manifests/misc/secrets.yaml
```

> Caso n√£o queira instalar o Reflactor para automatizar o processo de criar o secret em v√°rios namespaces diferentes, voc√™ pode replicar manualmente o secret para outro namespace executando este comando:
`kubectl get secret minio-secrets -n deepstorage -o yaml | sed s/"namespace: deepstorage"/"namespace: processing"/| kubectl apply -n processing -f -`

Uma vez que os secrets estejam configurados, √© poss√≠vel instalar os bancos de dados e o storage do pipeline de dados com o seguinte comando:

```sh
# databases
kubectl apply -f manifests/database/postgres.yaml
# deep storage
kubectl apply -f manifests/deepstorage/minio.yaml
```

Por fim, instale o Spark e o Airflow, juntamente com suas permiss√µes para executar os processos do Spark, executando os seguintes comandos:

```sh
# add & update helm list repos
helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
helm repo add apache-airflow https://airflow.apache.org/
helm repo update
```

```sh
# processing
kubectl apply -f manifests/processing/spark.yaml
```
<!-- Para criar um imagem do airflow com algumas libs inclusas, para isto execute o seguinte comando:
```sh 
eval $(minikube docker-env)
docker build -f images/airflow/dockerfile images/airflow/ -t airflow:0.1
``` -->

Antes de instalar o Airflow, √© preciso atender a um requisito: criar um secret contendo sua `chave ssh`, para que o Airflow possa baixar as `DAGs` necess√°rias por meio do `gitSync`. √â poss√≠vel criar esse secret com o seguinte comando:

> Lembrando que voc√™ deve ter a `chave ssh` configurada em sua m√°quina.

```sh
kubectl create secret generic airflow-ssh-secret --from-file=gitSshKey=$HOME/.ssh/id_ed25519 -n orchestrator
```

```sh
# orchestrator
kubectl apply -f manifests/orchestrator/airflow.yaml
```

Em seguida, instale as configura√ß√µes de acesso:

```sh
kubectl apply -f manifests/misc/access-control.yaml
```

Para que seja possivel o Ariflow executar de maneira independente os processos spark √© preciso que ele tenha uma conex√£o com o cluster, e para isto √© necessario passar essa informa√ß√£o ao Airflow. Para adicionar a conex√£o com o cluster ao Airflow execute:
```sh
kubectl get pods --no-headers -o custom-columns=":metadata.name" -n orchestrator | grep scheduler | xargs -i sh -c 'kubectl cp images/airflow/connections.json orchestrator/{}:./ -c scheduler | kubectl -n orchestrator exec {} -- airflow connections import connections.json'
```
<!-- export SCHEDULER_POD_NAME="$(kubectl get pods --no-headers -o custom-columns=":metadata.name" -n orchestrator | grep scheduler)"
kubectl cp images/airflow/connections.json orchestrator/$SCHEDULER_POD_NAME:./ -c scheduler
kubectl -n orchestrator exec $SCHEDULER_POD_NAME -- airflow connections import connections.json -->

√ìtimo, agora que voc√™ configurou as ferramentas necess√°rias, temos o ambiente de desenvolvimento e de execu√ß√£o instalado e pronto para uso.

### Executando o projeto


Antes de tudo, √© necess√°rio possuir uma `imagem do Spark` que contenha todos os JARs necess√°rios para a execu√ß√£o do nosso pipeline. Para criar uma imagem do Spark com essas especifica√ß√µes, execute:

```sh
eval $(minikube docker-env)
docker build --no-cache -f images/spark/dockerfile images/spark/ -t spark:0.1
```
Neste projeto, est√° sendo utilizada a vers√£o 3.3.2 do Spark e a vers√£o 2.2.0 do Delta, juntamente com todas as suas bibliotecas e JARs nas vers√µes compat√≠veis, seguindo as compatibilidades do Delta [neste link](https://docs.delta.io/latest/releases.html) e neste link.

Ap√≥s a imagem do Spark ser criada, abra a interface web do Airflow. Caso n√£o saiba qual foi o IP atribu√≠do ao webserver do Airflow, execute o seguinte comando para descobrir o IP:

```sh
kubectl get services -n orchestrator -l component=webserver,argocd.argoproj.io/instance=airflow -o jsonpath="{.items[0].status.loadBalancer.ingress[0].ip}"
```

Uma vez na interface do Airflow, ative o pipeline de dados `pipeline-delta-lake-deep-dive-complete` e veja a m√°gica acontecer. Ou, se preferir, voc√™ tamb√©m pode executar cada etapa separadamente, seguindo a sequ√™ncia:
  * `ingestion-from-local-data-file-to-bronze-tables`
  * `transformation-and-enrichment-from-bronze-to-silver`
  * `delivery-data-from-silver-to-gold`

Caso n√£o deseje executar o pipeline pelo Airflow, voc√™ pode executar o pipeline de dados executando os seguintes comandos em sequ√™ncia:
```sh
kubectl apply -f dags/spark_jobs/ingestion_from_local_data_file_to_bronze_tables.yaml -n processing
kubectl apply -f dags/spark_jobs/transform_and_enrichment_from_bronze_to_silver.yaml -n processing
kubectl apply -f dags/spark_jobs/delivery_data_from_silver_to_gold.yaml -n processing
```
Para verificar os arquivos no `data lakehouse`, acesse a interface web do `MinIO` e use as credenciais de acesso encontradas no arquivo *[minio-secrets.yaml](/secrets/minio-secrets.yaml)* na pasta *[secrets](/secrets/)*. Caso n√£o saiba o IP atribu√≠do ao MinIO, execute:

```sh
kubectl get services -n deepstorage -l app.kubernetes.io/name=minio -o jsonpath="{.items[0].status.loadBalancer.ingress[0].ip}"
```
Caso queira obter as credenciais de acesso do `MinIO`, execute:
```sh
echo "user: $(kubectl get secret minio-secrets -n deepstorage -o jsonpath="{.data.root-user}" | base64 -d)"
echo "password: $(kubectl get secret minio-secrets -n deepstorage -o jsonpath="{.data.root-password}" | base64 -d)"
```

## Pipeline Spark


O Pipeline Spark √© um processo de tr√™s etapas que tem como objetivo criar uma camada de dados organizada e tratada para que possa ser utilizada por times de an√°lise de dados. As etapas incluem a ingest√£o dos dados brutos (na camada Bronze), o tratamento e organiza√ß√£o dos dados (na camada Silver) e a cria√ß√£o de uma tabela final que ser√° utilizada pelos cientistas de dados (na camada Gold).

Para este desafio foi escolhida 4 conjunto de dados **(`user`, `subscription`, `credit_card` e `movies`)**.
Os codigos spark foram escritos em `python` ***(Pyspark)*** e adicionados a uma [imagem docker](images/spark/dockerfile). Optei colocar todos os meus c√≥digos spark na mesma `imagem`, pela simplicidade de desenvolver e explicar. Apesar de que este pode n√£o ser a melhor pratica para esse tipo de problema(mas funciona).

Os dados da **`landing`** disponibilizados pelo desafio, tamb√©m foram incluidos na `imagem`, os quais s√£o transformados em **tabelas `delta`** em um `lakehouse` criado no `minio`. Sei que esta n√£o foi a melhor pratica, mas esta tamb√©m foi uma escolha pela simplicidade de replica√ß√£o do projeto *(e minha falta de tempo de colocar no bucket)*.

### Carregando os dados na **`Bronze`**

[Na primeira etapa do pipeline](/images/spark/ingestion_to_bronze.py), os dados brutos s√£o carregados da pasta landing (que est√£o na [imagem](/images/spark/dockerfile)) e transformados em tabelas Delta no lakehouse, criado no Minio. A cria√ß√£o de tabelas Delta facilita o gerenciamento dos dados, permitindo que novos dados possam ser adicionados e atualizados posteriormente. Tamb√©m s√£o adicionadas informa√ß√µes adicionais como ingestion_time e file_size, que podem ser √∫teis para an√°lises posteriores. √â possivel ver todos as informa√ß√µes adicionais nas linhas `56-63` do arquivo [ingestion_to_bronze.py](/images/spark/ingestion_to_bronze.py).

Como dito anteriormente foram escolhidos os dados de `user`, `subscription`, `credit card` e `movies`, segue o schema das tabelas **`delta`** de cada um apos a ingest√£o da `landing` para a **`bronze`**:

```sh
user
 |-- address: struct (nullable = true)
 |    |-- city: string (nullable = true)
 |    |-- coordinates: struct (nullable = true)
 |    |    |-- lat: double (nullable = true)
 |    |    |-- lng: double (nullable = true)
 |    |-- country: string (nullable = true)
 |    |-- state: string (nullable = true)
 |    |-- street_address: string (nullable = true)
 |    |-- street_name: string (nullable = true)
 |    |-- zip_code: string (nullable = true)
 |-- avatar: string (nullable = true)
 |-- credit_card: struct (nullable = true)
 |    |-- cc_number: string (nullable = true)
 |-- date_of_birth: string (nullable = true)
 |-- dt_current_timestamp: long (nullable = true)
 |-- email: string (nullable = true)
 |-- employment: struct (nullable = true)
 |    |-- key_skill: string (nullable = true)
 |    |-- title: string (nullable = true)
 |-- first_name: string (nullable = true)
 |-- gender: string (nullable = true)
 |-- id: long (nullable = true)
 |-- last_name: string (nullable = true)
 |-- password: string (nullable = true)
 |-- phone_number: string (nullable = true)
 |-- social_insurance_number: string (nullable = true)
 |-- subscription: struct (nullable = true)
 |    |-- payment_method: string (nullable = true)
 |    |-- plan: string (nullable = true)
 |    |-- status: string (nullable = true)
 |    |-- term: string (nullable = true)
 |-- uid: string (nullable = true)
 |-- user_id: long (nullable = true)
 |-- username: string (nullable = true)
 |-- ingestion_time: timestamp (nullable = false)
 |-- source_system: string (nullable = false)
 |-- user_name: string (nullable = false)
 |-- ingestion_type: string (nullable = false)
 |-- base_format: string (nullable = false)
 |-- file_size: integer (nullable = false)
 |-- rows_written: integer (nullable = false)
 |-- schema: string (nullable = false)
```
```sh
subscription
 |-- dt_current_timestamp: long (nullable = true)
 |-- id: long (nullable = true)
 |-- payment_method: string (nullable = true)
 |-- payment_term: string (nullable = true)
 |-- plan: string (nullable = true)
 |-- status: string (nullable = true)
 |-- subscription_term: string (nullable = true)
 |-- uid: string (nullable = true)
 |-- user_id: long (nullable = true)
 |-- ingestion_time: timestamp (nullable = false)
 |-- source_system: string (nullable = false)
 |-- user_name: string (nullable = false)
 |-- ingestion_type: string (nullable = false)
 |-- base_format: string (nullable = false)
 |-- file_size: integer (nullable = false)
 |-- rows_written: integer (nullable = false)
 |-- schema: string (nullable = false)
```
```sh
credit card
 |-- credit_card_expiry_date: string (nullable = true)
 |-- credit_card_number: string (nullable = true)
 |-- credit_card_type: string (nullable = true)
 |-- dt_current_timestamp: long (nullable = true)
 |-- id: long (nullable = true)
 |-- uid: string (nullable = true)
 |-- user_id: long (nullable = true)
 |-- ingestion_time: timestamp (nullable = false)
 |-- source_system: string (nullable = false)
 |-- user_name: string (nullable = false)
 |-- ingestion_type: string (nullable = false)
 |-- base_format: string (nullable = false)
 |-- file_size: integer (nullable = false)
 |-- rows_written: integer (nullable = false)
 |-- schema: string (nullable = false)
```
```sh
movies
 |-- adult: string (nullable = true)
 |-- belongs_to_collection: string (nullable = true)
 |-- dt_current_timestamp: long (nullable = true)
 |-- genres: string (nullable = true)
 |-- id: string (nullable = true)
 |-- imdb_id: string (nullable = true)
 |-- original_language: string (nullable = true)
 |-- original_title: string (nullable = true)
 |-- overview: string (nullable = true)
 |-- popularity: string (nullable = true)
 |-- production_companies: string (nullable = true)
 |-- production_countries: string (nullable = true)
 |-- release_date: string (nullable = true)
 |-- revenue: double (nullable = true)
 |-- status: string (nullable = true)
 |-- title: string (nullable = true)
 |-- user_id: long (nullable = true)
 |-- vote_average: double (nullable = true)
 |-- vote_count: double (nullable = true)
 |-- ingestion_time: timestamp (nullable = false)
 |-- source_system: string (nullable = false)
 |-- user_name: string (nullable = false)
 |-- ingestion_type: string (nullable = false)
 |-- base_format: string (nullable = false)
 |-- file_size: integer (nullable = false)
 |-- rows_written: integer (nullable = false)
 |-- schema: string (nullable = false)
```
[Na segunda etapa](/images/spark/bronze_to_silver.py), os dados de diferentes fontes, como **`user`**, **`subscription`**, **`credit_card`** e **`movies`**, s√£o tratados e organizados em tabelas de `dom√≠nio`. Nesta etapa, tabelas de `dom√≠nio` como **`subscribers`** e **`voters`** s√£o criadas, que s√£o basicamente jun√ß√µes de diferentes tabelas de fontes. Os dados s√£o tratados e renomeados para que sejam mais √∫teis para an√°lises futuras.

Nesta etapa tamb√©m foi adicionado a informa√ß√£o complementar **`processing_time`** em ambas as tabelas de `dom√≠nio`. Segue o schema das tabelas **`subscribers`** e **`voters`**, respectivamente:

 ```sh
 subscribers
 |-- user_id: long (nullable = true)
 |-- user_complete_name: string (nullable = false)
 |-- user_complete_address: string (nullable = false)
 |-- user_job: string (nullable = true)
 |-- user_ingestion_time: timestamp (nullable = true)
 |-- user_source_system: string (nullable = true)
 |-- user_user_name: string (nullable = true)
 |-- user_ingestion_type: string (nullable = true)
 |-- user_base_format: string (nullable = true)
 |-- user_file_size: integer (nullable = true)
 |-- user_rows_written: integer (nullable = true)
 |-- user_schema: string (nullable = true)
 |-- subscription_user_id: long (nullable = true)
 |-- subscription_plan: string (nullable = true)
 |-- subscription_price: decimal(4,2) (nullable = false)
 |-- subscription_status: string (nullable = true)
 |-- subscription_importance: string (nullable = true)
 |-- subscription_event_time: long (nullable = true)
 |-- credit_card_user_id: long (nullable = true)
 |-- credit_card_number: string (nullable = true)
 |-- credit_card_expiry_date: string (nullable = true)
 |-- credit_card_type: string (nullable = true)
 |-- credit_card_event_time: long (nullable = true)
 |-- credit_card_ingestion_time: timestamp (nullable = true)
 |-- credit_card_source_system: string (nullable = true)
 |-- credit_card_user_name: string (nullable = true)
 |-- credit_card_ingestion_type: string (nullable = true)
 |-- credit_card_base_format: string (nullable = true)
 |-- credit_card_file_size: integer (nullable = true)
 |-- credit_card_rows_written: integer (nullable = true)
 |-- credit_card_schema: string (nullable = true)
 |-- processing_time: timestamp (nullable = false)
 ```
 ```sh
voters
 |-- user_id: long (nullable = true)
 |-- user_complete_name: string (nullable = false)
 |-- user_complete_address: string (nullable = false)
 |-- user_job: string (nullable = true)
 |-- user_ingestion_time: timestamp (nullable = true)
 |-- user_source_system: string (nullable = true)
 |-- user_user_name: string (nullable = true)
 |-- user_ingestion_type: string (nullable = true)
 |-- user_base_format: string (nullable = true)
 |-- user_file_size: integer (nullable = true)
 |-- user_rows_written: integer (nullable = true)
 |-- user_schema: string (nullable = true)
 |-- movies_user_id: long (nullable = true)
 |-- movies_adult: string (nullable = true)
 |-- movies_title: string (nullable = true)
 |-- movies_popularity: double (nullable = true)
 |-- movies_vote_average: double (nullable = true)
 |-- movies_vote_count: double (nullable = true)
 |-- movies_release_date: string (nullable = true)
 |-- movies_genres_name: string (nullable = true)
 |-- movies_event_time: long (nullable = true)
 |-- movies_ingestion_time: timestamp (nullable = true)
 |-- movies_source_system: string (nullable = true)
 |-- movies_user_name: string (nullable = true)
 |-- movies_ingestion_type: string (nullable = true)
 |-- movies_base_format: string (nullable = true)
 |-- movies_file_size: integer (nullable = true)
 |-- movies_rows_written: integer (nullable = true)
 |-- movies_schema: string (nullable = true)
 |-- processing_time: timestamp (nullable = false)
 ```
[Na terceira etapa do pipeline](/images/spark/silver_to_gold.py), uma nova tabela √© criada na camada **`Gold`**, com as informa√ß√µes tratadas das tabelas de `dom√≠nio` da camada **`Silver`**. As tabelas **`subscribers`** e **`voters`** s√£o renomeadas como **`subers`** e **`voters`**, respectivamente, e novas `colunas` e c√°lculos s√£o adicionados para que sejam √∫teis para an√°lises futuras. Por fim, as tabelas resultantes s√£o entregues aos cientistas de dados para que possam ser utilizadas em an√°lises mais aprofundadas. Segue o schema de ambas as tabelas:

 ```sh
 subers
 |-- id: long (nullable = true)
 |-- name: string (nullable = true)
 |-- address: string (nullable = true)
 |-- plan: string (nullable = true)
 |-- importance: string (nullable = true)
 |-- status: string (nullable = true)
 |-- card: string (nullable = true)
 |-- time_to_process: long (nullable = true)
 |-- event_time: timestamp (nullable = false)
```
```sh
voters
 |-- id: long (nullable = true)
 |-- name: string (nullable = true)
 |-- title: string (nullable = true)
 |-- popularity: double (nullable = true)
 |-- average: double (nullable = true)
 |-- count: double (nullable = true)
 |-- release: string (nullable = true)
 |-- genre: string (nullable = true)
 |-- time_to_process: long (nullable = true)
 |-- event_time: timestamp (nullable = false)
 ```

Certifique-se de testar e validar seus pipelines de dados antes de implant√°-los em produ√ß√£o. Isso ajudar√° a garantir que seus processos estejam funcionando corretamente e que os dados estejam sendo tratados de maneira apropriada.
<!--
kubectl apply -f dags/spark_jobs/delivery_data_from_silver_to_gold.yaml -n processing
kubectl logs -f transformation-and-enrichment-from-bronze-to-silver -n processing
kubectl delete sparkapplication delivery-data-from-silver-to-gold -n processing
 -->
## Estrutura de Arquivos

A estrutura de pastas est√° da seguinte maneira:

```bash
.
‚îú‚îÄ‚îÄ access-control
‚îú‚îÄ‚îÄ dags
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ spark_jobs
‚îú‚îÄ‚îÄ images
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ spark
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ landing
‚îú‚îÄ‚îÄ manifests
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ database
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ deepstorage
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ management
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ misc
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ monitoring
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ orchestrator
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ processing
‚îî‚îÄ‚îÄ secrets
# 35 directories, 327 files
```

Ser√£o explicados os arquivos e diret√≥rios na se√ß√£o de [Edi√ß√£o](#edi√ß√£o).

---
### Edi√ß√£o

Nesta se√ß√£o haver√£o instru√ß√µes caso voc√™ queira editar o projeto, explicando para que os diret√≥rios s√£o utilizados e tamb√©m os arquivos de configura√ß√£o.

- **[access-control](/access-control/)** - Diret√≥rio contendo todos os arquivos de aplica√ß√£o do projeto, √© criado um diret√≥rio `manifests` para que o c√≥digo da aplica√ß√£o possa ser isolado em um diret√≥rio e facilmente portado para outros projetos, se necess√°rio;

- **[manifests](/manifests/)** - Diret√≥rio contendo todos os arquivos de aplica√ß√£o do projeto, √© criado um diret√≥rio `manifests` para que o c√≥digo da aplica√ß√£o possa ser isolado em um diret√≥rio e facilmente portado para outros projetos, se necess√°rio;

  - **[database](/manifests/database/)** - Diret√≥rio para guardar os arquivos de configura√ß√£o das aplica√ß√µes de database, por exemplo, a configura√ß√£o de instala√ß√£o da aplica√ß√£o **[postgres](/manifests/database/postgres.yaml)**;

to do o resto

<!-- CONTRIBUTING -->

## Contribui√ß√£o

Contribui√ß√µes s√£o o que fazem a comunidade open source um lugar incr√≠vel para aprender, inspirar e criar. Qualquer contribui√ß√£o que voc√™ fizer ser√° **muito apreciada**.

1. Fa√ßa um Fork do projeto
2. Crie uma Branch para sua Feature (`git checkout -b feature/FeatureIncrivel`)
3. Adicione suas mudan√ßas (`git add .`)
4. Comite suas mudan√ßas (`git commit -m 'Adicionando uma Feature incr√≠vel!`)
5. Fa√ßa o Push da Branch (`git push origin feature/FeatureIncrivel`)
6. Abra um Pull Request

<!-- LICENSE -->


## üìå Suporte

Entre em contato comigo em um dos seguintes lugares!

- Linkedin em [Gerson Santos](https://www.linkedin.com/in/gerson-santos-a1442a90/)
- Instagram [gersonrsantos](https://www.instagram.com/gersonrsantos/)

---

## üìù Licen√ßa

<img alt="License" src="https://img.shields.io/badge/license-MIT-%2304D361?color=rgb(89,101,224)">

Distribu√≠do sob a licen√ßa MIT. Veja [LICENSE](LICENSE) para mais informa√ß√µes.

### üì± Social

Me acompanhe nas minhas redes sociais.

<p align="center">

 <a href="https://twitter.com/gersonrs3" target="_blank" >
     <img alt="Twitter" src="https://img.shields.io/badge/-Twitter-9cf?logo=Twitter&logoColor=white"></a>

  <a href="https://instagram.com/gersonrsantos" target="_blank" >
    <img alt="Instagram" src="https://img.shields.io/badge/-Instagram-ff2b8e?logo=Instagram&logoColor=white"></a>

  <a href="https://www.linkedin.com/in/gersonrsantos/" target="_blank" >
    <img alt="Linkedin" src="https://img.shields.io/badge/-Linkedin-blue?logo=Linkedin&logoColor=white"></a>

  <a href="https://t.me/gersonrsantos" target="_blank" >
    <img alt="Telegram" src="https://img.shields.io/badge/-Telegram-blue?logo=Telegram&logoColor=white"></a>

  <a href="mailto:gersonrodriguessantos8@gmail.com" target="_blank" >
    <img alt="Email" src="https://img.shields.io/badge/-Email-c14438?logo=Gmail&logoColor=white"></a>

</p>

---

Feito com ‚ù§Ô∏è by **Gerson**
